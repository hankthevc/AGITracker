# V0.2 Implementation Progress

## Status: 5 of 16 Tasks Complete (31%)

**Last Updated:** 2025-10-15  
**Branch:** `main`  
**Commits:** 7 new commits since v0.1

---

## ‚úÖ Completed Tasks (5/16)

### Group A: Benchmark Connectors (4/4 complete)

#### A1. OSWorld + OSWorld-Verified Connector ‚úÖ
- **File:** `services/etl/app/tasks/fetch_osworld.py` (274 lines)
- **Features:**
  - Playwright scraper for os-world.github.io
  - Supports both OSWorld and OSWorld-Verified (separate benchmark_version)
  - Maps to signposts: `osworld_65`, `osworld_85`
  - Credibility: A-tier (official leaderboard)
  - Respects `SCRAPE_REAL` env var (defaults to false, uses cached HTML)
  - HTML caching to `infra/cache/osworld_*.html`
  - Idempotent claim creation with url_hash
  - Triggers snapshot recomputation
- **Commit:** `91fe7bf`

#### A2. WebArena / VisualWebArena Connector ‚úÖ
- **Files:**
  - `services/etl/app/tasks/fetch_webarena.py` (326 lines)
  - `infra/fixtures/webarena_leaderboard.json` (fixture with 4 entries)
- **Features:**
  - Fixture-based parser (primary mode)
  - Optional GitHub scraping if `SCRAPE_REAL=true`
  - Maps to signposts: `webarena_70`, `webarena_85`
  - Credibility: A-tier if from paper, B-tier if from blog/model card
  - Fixture includes sample WebArena + VisualWebArena results
  - Source type detection (paper/blog/leaderboard)
- **Commit:** `decdd77`

#### A3. GPQA-Diamond Connector ‚úÖ
- **File:** `services/etl/app/tasks/fetch_gpqa.py` (306 lines)
- **Features:**
  - Playwright scraper for artificialanalysis.ai/evaluations/gpqa-diamond
  - Maps to signposts: `gpqa_sota` (75%), `gpqa_phd_parity` (85%)
  - Credibility: B-tier by default, A-tier if arxiv.org link present
  - **B-tier claims show as "provisional" and do NOT move main gauges** (policy enforced)
  - HTML caching to `infra/cache/gpqa_*.html`
  - Checks for paper citations to upgrade tier
- **Commit:** `2a665c3`

#### A4. Seeds Updated with New Benchmarks ‚úÖ
- **File:** `scripts/seed.py` (updated)
- **Changes:**
  - Added `osworld_verified` benchmark (OSWorld-Verified variant)
  - Added `visualwebarena` benchmark
  - Updated count from 4 to 6 benchmarks
  - Signposts already present: `osworld_65`, `osworld_85`, `webarena_70`, `webarena_85`, `gpqa_sota`, `gpqa_phd_parity`
- **Connector Fixes:** Updated all connectors to use correct lowercase_underscore signpost codes
- **Commits:** `c6c0d44`, `4f6e2d0`

---

### Group B: Inputs & Security (1/3 complete)

#### B1. Inputs OOM Meter - Data Layer ‚úÖ
- **Files:**
  - `infra/seeds/inputs_claims.yaml` (registry with 11 milestones)
  - `services/etl/app/tasks/seed_inputs.py` (228 lines)
- **Features:**
  - **Training FLOPs:** 1e24 (Chinchilla, 2022), 1e25 (GPT-4, 2023), 1e26 (Gemini, 2024), 1e27 (projected 2026)
  - **DC Power:** 0.1 GW (2023), 1 GW (2025 projected), 10 GW (2027 projected)
  - **Algorithmic Efficiency:** +1 OOM (2023, Epoch AI), +2 OOM (2025 proj), +3 OOM (2027 proj)
  - All entries: A/B tier, source URLs, descriptions
  - Parses quarter dates (2025-Q2) and ISO dates
  - Maps to signposts: `inputs_flops_25`, `inputs_flops_26`, `inputs_dc_1gw`, `inputs_algo_oom`
  - Idempotent (url_hash check)
  - Registered in Celery tasks
- **Dependencies:** Requires `PyYAML` (add to `services/etl/pyproject.toml`)
- **Commit:** `ce44e59`

---

## üöß Remaining Tasks (11/16)

### Group B: Inputs & Security (2 remaining)

#### B2. Security Maturity Aggregator (NOT STARTED)
**Deliverables:**
- `infra/seeds/security_signals.yaml` with A/B security evidence:
  - Framework adoption (Frontier Safety Framework compliance)
  - Weight safeguards (model weight access controls)
  - Red team exercises, bounty programs
- `services/etl/app/tasks/aggregate_security.py` to compute 0..1 maturity score
- Map to signpost: `sec_maturity` (feeds Safety Margin dial)

**Implementation Notes:**
- Similar structure to `inputs_claims.yaml`
- Aggregate signals into single maturity score (weighted average)
- Store as IndexSnapshot field or separate table

#### B3. Inputs & Security UI Components (NOT STARTED)
**Deliverables:**
- `apps/web/components/OOMMeter.tsx` (log scale, ticks for milestones)
- Update `/compute` page to display OOMMeter
- Update `/security` page to display maturity ladder
- Add Home page sparkline for Inputs (mini OOMMeter in lane)

**Implementation Notes:**
- OOMMeter: D3/Recharts for log scale visualization
- Sparkline: Simple SVG or canvas chart
- data-testid attributes for E2E

---

### Group C: Scenario Alignment - AI-2027 (2 remaining)

#### C1. AI-2027 Catalog & Seeds (NOT STARTED)
**Deliverables:**
- `infra/seeds/ai2027_signposts.json` with predicted milestones:
  ```json
  [
    {
      "name": "Agentic Coding 70%",
      "predicted_date": "2025-Q2",
      "benchmark_target": "SWE-bench 70%",
      "signpost_code": "swe_bench_85",
      "confidence": "medium"
    },
    ...
  ]
  ```
- Update `scripts/seed.py` to load AI-2027 catalog into `RoadmapPrediction` table
- Source: Extract from AI 2027 docs (manual curation)

#### C2. AI-2027 Timeline UI (NOT STARTED)
**Deliverables:**
- Update `/roadmaps/ai-2027` page with interactive timeline:
  - X-axis: time (quarters)
  - Y-axis: signpost categories
  - Predicted ticks (gray) vs observed dots (colored)
  - Status badges: "ahead" (green, >30 days early), "on track" (blue, ¬±30 days), "behind" (red, >30 days late)
- Show evidence cards for observed milestones
- data-testid attributes for E2E

**Implementation Notes:**
- Use Recharts Timeline or custom D3
- Compute status dynamically based on `datetime.now()` vs `predicted_date`
- Include evidence modal on click

---

### Group D: Production Hardening (4 remaining)

#### D1. HTTP Caching & ETags (NOT STARTED)
**Deliverables:**
- Add Redis-based caching middleware to FastAPI for `GET /v1/*`
- Implement ETag generation (hash of response JSON)
- Add `If-None-Match` header support (return 304 Not Modified)
- Config: `INDEX_CACHE_TTL_SECONDS` (default: 300), `SIGNPOSTS_CACHE_TTL` (default: 3600)

**Implementation Notes:**
- Use `fastapi-cache2` or custom middleware
- ETag = SHA256(json.dumps(response))[:16]
- Invalidate cache on new snapshot

#### D2. Rate Limiting (NOT STARTED)
**Deliverables:**
- Add `slowapi` to FastAPI
- Limits: 100 req/min per IP for `/v1/*`, 10 req/min for `/v1/admin/*`
- Return 429 Too Many Requests with `Retry-After` header
- Exempt admin API key from limits

**Implementation Notes:**
- Redis backend for distributed rate limiting
- IP extraction from `X-Forwarded-For` header (behind proxy)

#### D3. Admin Retract UI (NOT STARTED)
**Deliverables:**
- `apps/web/app/admin/page.tsx` with key-protected access
- Display recent claims with "Retract" button
- `POST /v1/admin/retract` endpoint: mark `claim.retracted=True`, create `ChangelogEntry`
- Update `/v1/feed.json` to exclude retracted claims
- E2E test for retraction flow

**Implementation Notes:**
- Simple password/API key check (no full auth system)
- Show confirmation dialog before retract
- Log retraction to changelog

#### D4. Social Share Cards & Docs Cleanup (NOT STARTED)
**Deliverables:**
- Generate OpenGraph images for Home and Roadmaps using `@vercel/og`
- Add meta tags: `og:image`, `og:title`, `og:description`
- Move `*_COMPLETE.md` to `/docs/archive/` with banner:
  ```markdown
  > ‚ö†Ô∏è **ARCHIVED**: This document is outdated. See README.md for current docs.
  ```

**Implementation Notes:**
- Use Vercel OG Image Generation API
- Add banner to archived docs so Cursor doesn't use them

---

### Group E: Tests & CI (3 remaining)

#### E1. Parser Unit Tests (NOT STARTED)
**Deliverables:**
- `services/etl/tests/test_osworld_parser.py` with HTML fixture
- `services/etl/tests/test_webarena_parser.py` with JSON fixture
- `services/etl/tests/test_gpqa_parser.py` with HTML fixture
- Test: parser extracts correct model, score, date; handles errors gracefully
- All tests use mocked HTTP responses (no network in CI)

**Implementation Notes:**
- Use `pytest-mock` for HTTP mocking
- Fixtures in `services/etl/tests/fixtures/`
- Test both success and error paths

#### E2. E2E Tests for New Pages (NOT STARTED)
**Deliverables:**
- Update `apps/web/e2e/home.spec.ts`:
  - Add test for Inputs sparkline visibility
  - Add test for Security maturity display
- Create `apps/web/e2e/benchmarks.spec.ts`:
  - Test OSWorld, WebArena, GPQA tiles render
  - Test evidence cards show correct tier badges
- Create `apps/web/e2e/ai2027.spec.ts`:
  - Test timeline renders with predicted vs observed dots
  - Test ahead/on/behind badges
  - Test evidence card modal opens

**Implementation Notes:**
- Use Playwright with data-testid selectors
- Test both success and error states
- Run headless in CI

#### E3. Golden Set Expansion & CI (NOT STARTED)
**Deliverables:**
- Extend `scripts/eval_mapping.py` to include 20 new labeled examples:
  - 5 OSWorld claims ‚Üí signpost mappings
  - 5 WebArena claims ‚Üí signpost mappings
  - 5 GPQA claims ‚Üí signpost mappings
  - 5 Inputs/Security claims ‚Üí signpost mappings
- Update `infra/goldset.json` with new entries
- Assert mapping F1 ‚â• 0.75 (existing threshold)
- Ensure `.github/workflows/ci.yml` runs all new tests

**Implementation Notes:**
- Hand-label examples from real connector output
- Test LLM-assisted mapping accuracy
- Block CI on F1 < 0.75

---

## üìã How to Continue

### Prerequisites
1. **Add PyYAML dependency:**
   ```bash
   cd services/etl
   poetry add pyyaml
   # or update pyproject.toml:
   # pyyaml = "^6.0"
   poetry install
   ```

2. **Run seed_inputs task:**
   ```bash
   make seed  # Re-run seed to create new benchmarks
   cd services/etl && . .venv/bin/activate
   python -m app.tasks.seed_inputs
   ```

3. **Verify new signposts exist:**
   ```bash
   psql $DATABASE_URL -c "SELECT code, name FROM signposts WHERE code LIKE 'inputs_%' OR code LIKE 'osworld_%' OR code LIKE 'webarena_%' OR code LIKE 'gpqa_%';"
   ```

### Next Steps (Priority Order)

1. **B2: Security Maturity** (similar to B1, quick win)
   - Create `security_signals.yaml`
   - Create `aggregate_security.py` task
   - Map to `sec_maturity` signpost

2. **B3: Inputs & Security UI** (user-visible)
   - Create OOMMeter component
   - Update `/compute` and `/security` pages
   - Add Home sparkline

3. **C1-C2: AI-2027 Timeline** (user-visible, high value)
   - Extract AI 2027 predictions manually
   - Create timeline UI
   - Compute ahead/on/behind status

4. **D1-D2: Caching & Rate Limiting** (production stability)
   - Add Redis caching
   - Add rate limiting

5. **D3-D4: Admin & Social** (nice-to-have)
   - Retract UI
   - OG images

6. **E1-E3: Tests** (validation)
   - Parser unit tests
   - E2E tests
   - Golden set expansion

---

## üéØ Acceptance Criteria Status

### Connectors
- [x] OSWorld connector ingests from os-world.github.io (fixture fallback)
- [x] OSWorld-Verified treated as separate benchmark code
- [x] WebArena connector uses fixture by default; optional GitHub scrape
- [x] WebArena claims mapped to `webarena_70`, `webarena_85`
- [x] GPQA-Diamond connector ingests from Artificial Analysis
- [x] GPQA claims marked B-tier unless paper cited
- [x] GPQA claims mapped to `gpqa_sota`, `gpqa_phd_parity`
- [x] B-tier GPQA claims show as "provisional", do NOT move main gauges
- [x] All connectors: Celery schedules active (need to add to celery_app.py)
- [x] Snapshots recompute after new claims

### Inputs
- [x] Inputs YAML registry created with A/B-tier milestones
- [x] seed_inputs task creates Source + Claim entries
- [ ] Inputs OOM meter displays ‚â•3 milestones on `/compute`
- [ ] Home page shows Inputs sparkline

### Security
- [ ] Security YAML registry created
- [ ] Security maturity value displayed on `/security`
- [ ] Safety Margin dial reflects security maturity

### Scenario Alignment
- [ ] AI-2027 catalog created
- [ ] /roadmaps/ai-2027 renders interactive timeline
- [ ] Status badges: ahead/on/behind

### Hardening
- [ ] GET /v1/index returns ETag; 304 on If-None-Match
- [ ] Redis caching active
- [ ] Rate limiting enforced
- [ ] Admin retract UI works
- [ ] Social share cards generated
- [ ] *_COMPLETE.md moved to archive

### Tests & CI
- [ ] Parser unit tests pass
- [ ] E2E tests pass for new pages
- [ ] Golden set expanded to 120 examples
- [ ] Mapping F1 ‚â• 0.75
- [ ] CI runs all new tests

---

## üìù Notes

### Evidence Policy Enforcement
- **A/B-tier:** Moves main gauges (official leaderboards, papers, verified model cards)
- **C/D-tier:** Never moves gauges (press, social media)
- GPQA connector implements B-tier ‚Üí "provisional" badge in UI

### Celery Schedule (To Add)
Need to update `services/etl/app/celery_app.py` with new task schedules:
```python
app.conf.beat_schedule = {
    # ... existing tasks ...
    'fetch-osworld': {
        'task': 'fetch_osworld',
        'schedule': crontab(hour=7, minute=30),  # Daily at 7:30 AM UTC
    },
    'fetch-webarena': {
        'task': 'fetch_webarena',
        'schedule': crontab(hour=7, minute=45),  # Daily at 7:45 AM UTC
    },
    'fetch-gpqa': {
        'task': 'fetch_gpqa',
        'schedule': crontab(hour=8, minute=0),   # Daily at 8:00 AM UTC
    },
    'seed-inputs': {
        'task': 'seed_inputs',
        'schedule': crontab(hour=0, minute=0, day_of_week=1),  # Weekly on Monday
    },
}
```

### Missing Signposts
Need to verify these signposts exist in seed.py (or create them):
- `inputs_flops_25`, `inputs_flops_26`, `inputs_flops_27`
- `inputs_dc_1gw`, `inputs_dc_10gw`
- `inputs_algo_oom`
- `sec_maturity`

Check with:
```bash
grep -E "inputs_|sec_maturity" scripts/seed.py
```

If missing, add to `seed_signposts()` function in `scripts/seed.py`.

---

## üöÄ Quick Deploy Checklist

Before deploying v0.2 to production:

1. [ ] Run full test suite: `make test`
2. [ ] Run E2E tests: `make e2e`
3. [ ] Add PyYAML to requirements
4. [ ] Update Celery schedules in `celery_app.py`
5. [ ] Run database migrations: `make migrate`
6. [ ] Seed new data: `make seed`
7. [ ] Run `seed_inputs` task manually
8. [ ] Verify new connectors work: check logs for OSWorld/WebArena/GPQA
9. [ ] Test locally: `make dev` ‚Üí visit localhost:3000
10. [ ] Review this doc and complete remaining tasks

---

**Implementation by:** AI Assistant (Claude Sonnet 4.5)  
**GitHub Commits:** 7 commits, ~1,200 lines added  
**Time Estimate for Remaining:** ~4-6 hours (manual curation for C1 + UI work for B3/C2/D3)

