# =============================================================================
# AGI Signpost Tracker - Environment Configuration
# =============================================================================
# Complete configuration reference for local development and production.
# Copy this file to `.env` and customize values as needed.
#
# Quick Start:
#   1. Copy: cp .env.example .env
#   2. Set DATABASE_URL to your PostgreSQL instance
#   3. Set REDIS_URL (optional, uses in-memory if empty)
#   4. Set ADMIN_API_KEY to a strong random value
#   5. Set OPENAI_API_KEY if using LLM features (optional)
# =============================================================================

# -----------------------------------------------------------------------------
# Core Database & Cache
# -----------------------------------------------------------------------------

# PostgreSQL connection string (required)
# Format: postgresql+psycopg://user:password@host:port/database
# Example: postgresql+psycopg://postgres:postgres@localhost:5432/agi_signpost_tracker
DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:5432/agi_signpost_tracker

# Redis connection string (optional - if empty, uses in-memory cache fallback)
# Format: redis://host:port/db
# Used for: Celery broker/backend, API response caching, rate limiting
REDIS_URL=redis://localhost:6379/0

# -----------------------------------------------------------------------------
# API Service Configuration
# -----------------------------------------------------------------------------

# Admin API Key (required in production)
# Used for protected endpoints:
#   - POST /v1/admin/retract (retract a claim/event)
#   - POST /v1/admin/recompute (trigger index recomputation)
#   - POST /v1/admin/event-links/{id}/approve (approve event mapping)
#   - POST /v1/admin/event-links/{id}/reject (reject event mapping)
# IMPORTANT: Change this to a strong random value in production
# Generate with: openssl rand -hex 32
ADMIN_API_KEY=change-me-in-production

# CORS Origins (comma-separated, no wildcards)
# Add your frontend domain for production
# Example: http://localhost:3000,https://your-app.vercel.app
CORS_ORIGINS=http://localhost:3000

# Rate Limiting
# Requests per minute per IP for public GET endpoints
# POST /v1/admin/* endpoints are not rate-limited but require ADMIN_API_KEY
RATE_LIMIT_PER_MINUTE=100

# -----------------------------------------------------------------------------
# HTTP Response Caching (seconds)
# -----------------------------------------------------------------------------

INDEX_CACHE_TTL_SECONDS=120           # /v1/index endpoint (2 minutes)
SIGNPOSTS_CACHE_TTL_SECONDS=300       # /v1/signposts endpoint (5 minutes)
EVIDENCE_CACHE_TTL_SECONDS=180        # /v1/evidence endpoint (3 minutes)
FEED_CACHE_TTL_SECONDS=300            # /v1/feed.json endpoint (5 minutes)
EVENTS_CACHE_TTL_SECONDS=180          # /v1/events endpoint (3 minutes)

# -----------------------------------------------------------------------------
# LLM Configuration (OpenAI)
# -----------------------------------------------------------------------------

# OpenAI API Key (optional)
# Used for:
#   - Event extraction from unstructured text
#   - Event-to-signpost mapping (fallback after rule-based matching)
# Leave empty to use rule-based extraction only (no LLM costs)
OPENAI_API_KEY=

# LLM Budget Guard (daily spending limit in USD)
# Default: $20/day
# Strategy: OpenAI primary, rule-based fallback when budget exhausted
# Tracked via Redis counter `llm_spend_today_usd`, resets at midnight UTC
# Models: GPT-4o-mini for extraction (~$0.15/1K tokens), GPT-4o for complex mapping
LLM_BUDGET_DAILY_USD=20

# Enable LLM Mapper (default: true if OPENAI_API_KEY is set)
# Set to false to disable LLM fallback in event mapper even if API key is present
# Useful for: CI, testing, or when you want deterministic rule-based mapping only
ENABLE_LLM=true

# -----------------------------------------------------------------------------
# News Ingestion & Scraping
# -----------------------------------------------------------------------------

# Scraping Mode (default: false)
# - false (default): Use fixtures only (safer for CI/dev, no network calls)
# - true: Enable real scraping (respects robots.txt, requires network)
# Note: Default is false to avoid accidental rate limiting in CI
SCRAPE_REAL=false

# Per-source real scraping flags (override SCRAPE_REAL for specific sources)
# Only active if SCRAPE_REAL=true or if specific source flag is set
ARXIV_REAL=false                      # arXiv RSS feed scraping
NEWS_REAL=false                       # Reuters/AP wire services
LABS_REAL=false                       # OpenAI/Anthropic/DeepMind blogs
SOCIAL_REAL=false                     # Twitter/Reddit (opt-in, D-tier)
LEADERBOARDS_REAL=false               # Live leaderboard scraping

# HTTP Client Settings (for scrapers)
HTTP_TIMEOUT_SECONDS=20               # Request timeout
HTTP_MAX_RETRIES=3                    # Retry attempts on failure
HTTP_BACKOFF_BASE_SECONDS=1           # Exponential backoff base (seconds)

# Robots.txt Compliance (always enabled)
# Scrapers automatically check robots.txt before fetching
# User-Agent: AGI-Tracker-Bot/1.0 (https://github.com/your-repo; contact@example.com)

# -----------------------------------------------------------------------------
# Evidence Policy (Immutable - Do Not Change)
# -----------------------------------------------------------------------------

# These values control how events affect the main gauges.
# Tier A (Primary): Peer-reviewed papers, official leaderboards → Moves gauges
# Tier B (Official Lab): Lab blog posts, model cards → Moves gauges (provisional)
# Tier C (Reputable Press): Reuters, AP, Bloomberg → "If true" analysis only
# Tier D (Social): Twitter, Reddit → "If true" analysis only
#
# Policy:
#   - Only A/B tier events can move main gauges
#   - B-tier events require A-tier corroboration within 14 days to persist
#   - C/D tier events NEVER move gauges (tracked for research only)
#
# HLE (Humanity's Last Exam):
#   - Remains monitor-only (first_class=false) until A-tier evidence is available
#   - Currently B-tier (provisional) due to known label quality issues
#
# Inputs & Security Gating:
#   - Overall index displays "N/A" until both Inputs and Security have non-zero progress
#   - This prevents misleading "0%" signals when data is simply missing

# -----------------------------------------------------------------------------
# Observability & Monitoring
# -----------------------------------------------------------------------------

# Sentry (optional - leave empty to disable error tracking)
SENTRY_DSN_API=                       # API/ETL service DSN
SENTRY_DSN_WEB=                       # Next.js web app DSN

# Healthchecks.io (optional - leave empty to disable task monitoring)
# Celery Beat pings this URL after each successful ETL cycle
HEALTHCHECKS_PING_URL=

# Logging Level
# Options: DEBUG | INFO | WARNING | ERROR
# Structured logs (JSON) include request_id for tracing
LOG_LEVEL=INFO

# Environment Tag (for Sentry, logs)
# Options: development | staging | production
ENVIRONMENT=development

# -----------------------------------------------------------------------------
# Web Frontend (apps/web)
# -----------------------------------------------------------------------------

# API Base URL (auto-detected if empty)
# - Empty (default): Auto-detects http://localhost:8000 in dev
# - Set explicitly for production: https://api.your-domain.com
NEXT_PUBLIC_API_URL=http://localhost:8000

# -----------------------------------------------------------------------------
# Testing & CI
# -----------------------------------------------------------------------------

# CI Mode (automatically set by GitHub Actions)
# When true: uses fixtures only, skips network calls, disables LLM
CI=false

# Test Database (optional - uses DATABASE_URL if empty)
# Recommended: Use a separate database for tests to avoid data conflicts
# TEST_DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:5432/agi_signpost_tracker_test
